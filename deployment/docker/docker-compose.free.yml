# Free Services Docker Compose Configuration
# Cost-effective D&D storytelling with OpenAI free tier optimization

version: '3.8'

services:
  web:
    build:
      context: ../..
      dockerfile: deployment/docker/Dockerfile.free
      args:
        - PIP_DEFAULT_TIMEOUT=300
        - PIP_RETRIES=5
    container_name: dnd-storytelling-free
    ports:
      - "8001:8000"
    environment:
      # SQLite Database (no PostgreSQL needed)
      - DATABASE_URL=sqlite:///data/dndstory.db

      # OpenAI Configuration (Free tier friendly)
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=gpt-3.5-turbo-16k
      - WHISPER_MODEL=base

      # Application Settings
      - SECRET_KEY=${SECRET_KEY:-dev-secret-key-change-in-production}
      - ENVIRONMENT=production
      - DEBUG=false

      # Performance Settings (Conservative for free usage)
      - MAX_FILE_SIZE=52428800
      - MAX_CONCURRENT_UPLOADS=2
      - PROCESSING_TIMEOUT=1200
      - WORKERS=2

      # Cost Control Features
      - MAX_TOKENS=2000
      - TEMPERATURE=0.7
      - ENABLE_CONFLUENCE=false

      # Optional Confluence (if you have it)
      - CONFLUENCE_URL=${CONFLUENCE_URL:-}
      - CONFLUENCE_API_TOKEN=${CONFLUENCE_API_TOKEN:-}

    volumes:
      - app_data:/data
      - app_uploads:/app/uploads
      - app_logs:/app/logs
      - app_temp:/app/temp

    working_dir: /app

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 60s
      timeout: 30s
      retries: 3
      start_period: 60s

    restart: unless-stopped

    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.25'

volumes:
  app_data:
    driver: local
  app_uploads:
    driver: local
  app_logs:
    driver: local
  app_temp:
    driver: local